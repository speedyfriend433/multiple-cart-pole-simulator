<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Advanced Multi-Pole Cart Balancing AI</title>
    <!-- Fix favicon 404 error -->
    <link rel="icon" type="image/x-icon" href="data:image/x-icon;base64,AAABAAEAEBAQAAEABAAoAQAAFgAAACgAAAAQAAAAIAAAAAEABAAAAAAAgAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAA/4QAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAERERERERERERAAAAAAAAERAQAAAAAAEBEAEAAAAAEAEQABAAAAEAARAAAQAAEAABEAAAEAEAAAEQAAABEAAAARAAAAEQAAABEAAAEAEAAAEQAAEAABAAARAAEAAAAQABEAEAAAAAEAEQEAAAAAABERERAAAAAAAAEREREREREREAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA">
    <style>
        /* Previous CSS remains the same */
    </style>
</head>
<body>
    <!-- Previous HTML remains the same -->
    <script>
        // Enhanced Neural Network with modern architecture
        class AdvancedNeuralNetwork {
            constructor(inputSize, outputSize) {
                this.inputSize = inputSize;
                this.outputSize = outputSize;
                
                // Architecture sizes
                this.layer1Size = 256;
                this.layer2Size = 128;
                this.layer3Size = 64;
                
                // Initialize weights with Xavier/Glorot initialization
                this.weights1 = this.initializeWeights(inputSize, this.layer1Size);
                this.weights2 = this.initializeWeights(this.layer1Size, this.layer2Size);
                this.weights3 = this.initializeWeights(this.layer2Size, this.layer3Size);
                this.weights4 = this.initializeWeights(this.layer3Size, outputSize);
                
                // Initialize biases
                this.biases1 = new Array(this.layer1Size).fill(0);
                this.biases2 = new Array(this.layer2Size).fill(0);
                this.biases3 = new Array(this.layer3Size).fill(0);
                this.biases4 = new Array(outputSize).fill(0);
                
                // Hyperparameters
                this.learningRate = 0.001;
                this.beta1 = 0.9; // Adam optimizer parameter
                this.beta2 = 0.999; // Adam optimizer parameter
                this.epsilon = 1e-8;
                
                // Initialize Adam optimizer parameters
                this.initializeAdam();
            }

            initializeWeights(inputDim, outputDim) {
                // Xavier/Glorot initialization
                const limit = Math.sqrt(6 / (inputDim + outputDim));
                return Array(inputDim).fill().map(() =>
                    Array(outputDim).fill().map(() =>
                        (Math.random() * 2 - 1) * limit
                    )
                );
            }

            initializeAdam() {
                // Initialize momentum and velocity terms for Adam
                this.m1 = this.createZeroMatrix(this.inputSize, this.layer1Size);
                this.v1 = this.createZeroMatrix(this.inputSize, this.layer1Size);
                this.m2 = this.createZeroMatrix(this.layer1Size, this.layer2Size);
                this.v2 = this.createZeroMatrix(this.layer1Size, this.layer2Size);
                this.m3 = this.createZeroMatrix(this.layer2Size, this.layer3Size);
                this.v3 = this.createZeroMatrix(this.layer2Size, this.layer3Size);
                this.m4 = this.createZeroMatrix(this.layer3Size, this.outputSize);
                this.v4 = this.createZeroMatrix(this.layer3Size, this.outputSize);
                
                this.t = 0; // Time step for Adam
            }

            createZeroMatrix(rows, cols) {
                return Array(rows).fill().map(() => Array(cols).fill(0));
            }

            leakyReLU(x, alpha = 0.01) {
                return x > 0 ? x : alpha * x;
            }

            leakyReLUDerivative(x, alpha = 0.01) {
                return x > 0 ? 1 : alpha;
            }

            forward(input) {
                // Store inputs for backprop
                this.lastInput = input;

                // First hidden layer
                this.layer1 = input.map((_, i) =>
                    this.weights1[i].reduce((sum, w, j) => 
                        sum + w * input[j], 0) + this.biases1[i]
                );
                this.layer1 = this.layer1.map(x => this.leakyReLU(x));

                // Second hidden layer
                this.layer2 = this.layer1.map((_, i) =>
                    this.weights2[i].reduce((sum, w, j) => 
                        sum + w * this.layer1[j], 0) + this.biases2[i]
                );
                this.layer2 = this.layer2.map(x => this.leakyReLU(x));

                // Third hidden layer
                this.layer3 = this.layer2.map((_, i) =>
                    this.weights3[i].reduce((sum, w, j) => 
                        sum + w * this.layer2[j], 0) + this.biases3[i]
                );
                this.layer3 = this.layer3.map(x => this.leakyReLU(x));

                // Output layer
                const output = this.layer3.map((_, i) =>
                    this.weights4[i].reduce((sum, w, j) => 
                        sum + w * this.layer3[j], 0) + this.biases4[i]
                );

                // Apply tanh to output for bounded actions
                return Math.tanh(output[0]);
            }

            train(state, action, reward) {
                this.t += 1; // Increment time step
                
                // Forward pass
                const prediction = this.forward(state);
                const error = reward * (action - prediction);

                // Backpropagation
                let gradient = error;
                
                // Update weights using Adam optimizer
                this.updateLayerAdam(this.weights4, this.layer3, gradient, this.m4, this.v4);
                gradient = this.backpropLayer(this.weights4, gradient, this.layer3, true);
                
                this.updateLayerAdam(this.weights3, this.layer2, gradient, this.m3, this.v3);
                gradient = this.backpropLayer(this.weights3, gradient, this.layer2);
                
                this.updateLayerAdam(this.weights2, this.layer1, gradient, this.m2, this.v2);
                gradient = this.backpropLayer(this.weights2, gradient, this.layer1);
                
                this.updateLayerAdam(this.weights1, this.lastInput, gradient, this.m1, this.v1);
            }

            updateLayerAdam(weights, inputs, gradient, m, v) {
                const lr_t = this.learningRate * 
                    Math.sqrt(1 - Math.pow(this.beta2, this.t)) / 
                    (1 - Math.pow(this.beta1, this.t));

                for(let i = 0; i < weights.length; i++) {
                    for(let j = 0; j < weights[i].length; j++) {
                        const grad = gradient * inputs[j];
                        
                        // Update momentum
                        m[i][j] = this.beta1 * m[i][j] + (1 - this.beta1) * grad;
                        
                        // Update velocity
                        v[i][j] = this.beta2 * v[i][j] + (1 - this.beta2) * grad * grad;
                        
                        // Update weights
                        weights[i][j] += lr_t * m[i][j] / (Math.sqrt(v[i][j]) + this.epsilon);
                    }
                }
            }

            backpropLayer(weights, gradient, inputs, isOutput = false) {
                const nextGradient = new Array(inputs.length).fill(0);
                
                for(let i = 0; i < weights.length; i++) {
                    for(let j = 0; j < weights[i].length; j++) {
                        nextGradient[j] += weights[i][j] * gradient;
                    }
                }
                
                return nextGradient.map((grad, i) => 
                    grad * (isOutput ? 1 : this.leakyReLUDerivative(inputs[i]))
                );
            }
        }

        // Main application logic
        class CartPoleAI {
            constructor() {
                this.numPoles = 1;
                this.system = new MultiPoleSystem(this.numPoles);
                this.visualizer = new CartPoleVisualizer('cartPoleCanvas');
                this.network = new AdvancedNeuralNetwork(2 + 2 * this.numPoles, 1);
                this.isTraining = false;
                this.episode = 0;
                this.setupEventListeners();
            }

            setupEventListeners() {
                document.getElementById('poleCount').addEventListener('change', (e) => {
                    this.numPoles = parseInt(e.target.value);
                    this.reset();
                });

                document.getElementById('startTraining').addEventListener('click', () => {
                    this.isTraining = true;
                    this.train();
                });

                document.getElementById('stopTraining').addEventListener('click', () => {
                    this.isTraining = false;
                });

                document.getElementById('resetSystem').addEventListener('click', () => {
                    this.reset();
                });
            }

            reset() {
                this.system = new MultiPoleSystem(this.numPoles);
                this.network = new NeuralNetwork(2 + 2 * this.numPoles, 24, 1);
                this.episode = 0;
                this.updateStats(0);
            }

            updateStats(reward) {
                document.getElementById('stats').textContent = 
                    `Training Statistics: Episode: ${this.episode} | Reward: ${reward.toFixed(2)}`;
            }

            async train() {
                while(this.isTraining) {
                    let state = this.system.reset();
                    let totalReward = 0;
                    
                    for(let step = 0; step < 500 && this.isTraining; step++) {
                        // Get action from network
                        const action = this.network.forward(state) * 10; // Scale action
                        
                        // Take step in environment
                        const result = this.system.step(action);
                        
                        // Train network
                        this.network.train(state, action/10, result.reward);
                        
                        // Update state and accumulate reward
                        state = result.state;
                        totalReward += result.reward;
                        
                        // Visualize
                        this.visualizer.draw(state, this.numPoles);
                        
                        if(result.done) break;
                        
                        // Add small delay for visualization
                        await new Promise(r => setTimeout(r, 20));
                    }
                    
                    this.episode++;
                    this.updateStats(totalReward);
                }
            }
        }

        // Initialize application
        const app = new CartPoleAI();
    </script>
</body>
</html>
